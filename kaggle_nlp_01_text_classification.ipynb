{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Text Classification with SpaCy\n",
    "\n",
    "- a common task in NLP is **text classification**\n",
    "    - this is classificaiton in the conventional ML sense and is applied to text\n",
    "\n",
    "- examples\n",
    "    - spam detection \n",
    "    - sentiment analysis\n",
    "    - tagging customer queries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***\n",
    "\n",
    "## Spam Detection with SpaCy\n",
    "\n",
    "- this classifier will detect spam messages \n",
    "- a common functionality in most email client "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import pandas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "source": [
    "### Load labelled data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "spam = pd.read_csv('kaggle_data/spam.csv')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": []
  },
  {
   "source": [
    "### Check head of dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>spam</td>\n      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ham</td>\n      <td>Even my brother is not like to speak with me. ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ham</td>\n      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>spam</td>\n      <td>WINNER!! As a valued network customer you have...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>spam</td>\n      <td>Had your mobile 11 months or more? U R entitle...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "spam.head(10)"
   ]
  },
  {
   "source": [
    "- here, `ham` is the label for non-spam data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***\n",
    "\n",
    "## Numerical Representation of Text\n",
    "\n",
    "- Machine learning models don't learn from raw text data\n",
    "\n",
    "    - Instead, you need to convert the text to something numeric\n",
    "    \n",
    "    - The simplest common representation is a variation of one-hot encoding\n",
    "\n",
    "- once we have a numerical representation of the raw text, those numerical vectors can be fed into any machine learning model\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "### Building the Vocabulary\n",
    "\n",
    "- The vocabulary is built from all the tokens (terms) in the corpus (the collection of documents)\n",
    "\n",
    "**Example**\n",
    "\n",
    "- As an example, take the sentences \n",
    "    - \"Tea is life. Tea is love.\" and \n",
    "\n",
    "    - \"Tea is healthy, calming, and delicious.\" as our corpus. \n",
    "    \n",
    "- The vocabulary then is `{\"tea\", \"is\", \"life\", \"love\", \"healthy\", \"calming\", \"and\", \"delicious\"}` (ignoring punctuation)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Bag of Words (One-Hot-Encoding for text) Representation\n",
    "\n",
    "- You represent each document as a vector of term frequencies for each term in the vocabulary\n",
    "\n",
    "- so for the sentences:\n",
    "    - \"Tea is life. Tea is love.\" and \n",
    "\n",
    "    - \"Tea is healthy, calming, and delicious.\" as our corpus\n",
    "\n",
    "- vector representation is given by\n",
    "    -   `v_1 = [2 2 1 1 0 0 0 0]` and \n",
    "    -   `v_2 = [1 1 0 0 1 1 1 1]`  \n",
    "\n",
    "- this vector representation is called the **bag-of-words** representation\n",
    "\n",
    "- vocabularies typically have 10k-90k terms, so these **bag-of-words** vectors can be very large"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### TF-IDF Representation\n",
    "\n",
    "- Another common representation of text in numerical form is **TF-IDF** (Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "- TF-IDF is similar to bag of words except that each term count is scaled by the term's frequency in the corpus\n",
    "    - Using TF-IDF can potentially improve your models. You won't need it here. Feel free to look it up though\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***\n",
    "\n",
    "## Building a Bag-of-Words Prediction Model\n",
    "\n",
    "- with the `TextCategorizer` class, spaCy handles \n",
    "    - bag of words conversion and \n",
    "    \n",
    "    - building a simple linear model for you \n",
    "    \n",
    "### Pipes\n",
    "\n",
    "- `TextCategorizer` is actually a spaCY **pipe**\n",
    "\n",
    "- now, **pipes** are classes for \n",
    "\n",
    "    - processing \n",
    "    \n",
    "    - transformation \n",
    "\n",
    "    of tokens\n",
    "\n",
    "#### Default Pipes\n",
    "\n",
    "- `nlp = spacy.load('en')` actually creates a model with default pipes that perform part of speech tagging, entity recognition and other transformations\n",
    "\n",
    "- when text is run through this `nlp` model by doing `doc = nlp(\"Some text here\")`\n",
    "\n",
    "    - the output of the pipes are atached to the tokens in the `doc` object \n",
    "    \n",
    "    - the lemmas that are output with `token.lemma_` comes from one these pipes\n",
    "\n",
    "#### Modifying Model Pipes\n",
    "\n",
    "- pipes maybe added or removed from models \n",
    "\n",
    "- to build a model from scratch with only the desired pipes, create an empty model first\n",
    "\n",
    "    - `nlp = spacy.blank(\"en\")`\n",
    "\n",
    "    - the empty model still comes with a tokenizer, since text representation models always have a tokenizer\n",
    "\n",
    "- then add the `TextCategorizer` pipe to the empty model for instance "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}